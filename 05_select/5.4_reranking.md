## 5.4 重排序与相关性优化

### 5.4.1 为什么需要重排序

向量检索虽然高效，但存在局限：
- 嵌入是预计算的，无法考虑查询特定的语义
- 向量相似不等于真正的相关性
- 检索时只考虑局部匹配，缺乏全局视角

**重排序**（Reranking）是对初步检索结果进行二次排序的技术，能够显著提升最终结果的相关性。

### 5.4.2 两阶段检索架构

```mermaid
graph LR
    A["查询"] --> B["第一阶段：召回"]
    B --> C["候选集"]
    C --> D["第二阶段：重排序"]
    D --> E["最终结果"]
```

- **第一阶段**：快速召回大量候选（如 Top-100）
- **第二阶段**：精细排序，选出最相关结果（如 Top-5）

这种架构在效率和精度之间取得平衡。

### 5.4.3 重排序技术

#### 交叉编码器

**原理**：将查询和文档拼接输入模型，直接输出相关性得分。

```
输入：[CLS] 查询 [SEP] 文档 [SEP]
输出：相关性分数 (0-1)
```

**优点**：精度最高，能够捕捉查询-文档交互
**缺点**：计算成本高，无法预计算

**常用模型**：
- BGE-Reranker
- Cohere Rerank
- ms-marco 系列

#### LLM 重排序

**原理**：使用语言模型判断相关性或排序。

方式一：逐对比较
```
"以下两段内容哪个与查询更相关？
查询：...
内容A：...
内容B：..."
```

方式二：直接评分
```
"评估以下内容与查询的相关性（1-10分）：
查询：...
内容：..."
```

**优点**：灵活，可使用任何 LLM
**缺点**：成本高，延迟大

#### 混合打分

结合多个信号进行打分：

```
最终分数 = α × 语义分数 + β × 重排序分数 + γ × 其他信号
```

其他信号可以包括：
- 关键词匹配得分
- 文档权威性
- 时间新鲜度
- 用户行为数据

### 5.4.4 重排序实践

**召回候选数量**

- 太少：可能遗漏相关结果
- 太多：增加重排序成本

通常召回 20-100 条供重排序。

**重排序结果数量**

根据后续使用确定：
- 问答场景：通常 3-5 条
- 综合分析：可能需要 10+ 条

**性能优化**

- 批量处理减少调用次数
- 使用轻量级重排序模型
- 缓存频繁查询的结果

### 5.4.5 相关性优化的其他技术

**查询优化**

在检索前优化查询：
- 语义扩展：添加同义词
- 意图识别：理解查询真实意图
- 子查询分解：复杂查询拆分

**结果多样化**

避免返回重复或相似的结果：
- MMR（最大边际相关性）
- 聚类去重

**反馈学习**

利用用户反馈改进排序：
- 点击数据
- 满意度评分
- A/B 测试结果

### 5.4.6 重排序效果评估

常用评估指标：

| 指标 | 含义 |
|------|------|
| MRR | 平均倒数排名，关注第一个相关结果位置 |
| NDCG | 归一化折扣累积增益，考虑排名位置 |
| Recall@K | Top-K 结果中的召回率 |
| Precision@K | Top-K 结果中的精确率 |

实践中应选择与业务目标相关的指标进行优化。
