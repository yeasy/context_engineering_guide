## 5.3 嵌入模型与语义搜索

### 嵌入的基本概念

**嵌入**（Embedding）是将文本转换为数值向量的过程。语义相近的文本在向量空间中距离也相近，这是语义搜索的数学基础。

嵌入模型的核心任务：将任意长度的文本映射到固定维度的向量空间，保持语义相似性。

### 嵌入模型的工作原理

```mermaid
graph LR
    A["输入文本"] --> B["分词"]
    B --> C["编码器"]
    C --> D["池化层"]
    D --> E["嵌入向量"]
```

主要步骤：
1. **分词**：将文本切分为 Token
2. **编码**：通过 Transformer 编码器获取上下文表示
3. **池化**：将多个 Token 表示合并为单一向量
4. **归一化**：可选，将向量归一化为单位长度

### 主流嵌入模型对比

| 模型 | 维度 | 最大长度 | 特点 |
|------|------|----------|------|
| text-embedding-3-small | 1536 | 8191 | OpenAI，平衡性能与成本 |
| text-embedding-3-large | 3072 | 8191 | OpenAI，最高精度 |
| BGE-Large-zh | 1024 | 512 | 中文优秀，开源 |
| BGE-M3 | 1024 | 8192 | 多语言，支持混合检索 |
| E5-Large | 1024 | 512 | 指令式嵌入 |
| Cohere Embed v3 | 1024 | 512 | 多语言，商业服务 |

### 嵌入模型选择因素

**质量需求**

- 高质量场景：选择能力更强的模型
- 一般场景：平衡模型可能足够

**语言支持**

- 纯中文：BGE 系列表现突出
- 多语言：BGE-M3、Cohere 等

**上下文长度**

- 长文档检索：需要支持更长输入的模型
- 短查询：大多数模型都能胜任

**成本与性能**

- 云服务：按调用计费，需要考虑成本
- 本地部署：需要考虑硬件资源

### 语义搜索实现

**相似度度量**

常用的相似度计算方法：

| 方法 | 公式 | 特点 |
|------|------|------|
| 余弦相似度 | cos(A, B) | 最常用，忽略向量长度 |
| 点积 | A · B | 快速计算 |
| 欧氏距离 | \|\|A - B\|\| | 考虑绝对位置 |

余弦相似度最为常用，因为它专注于方向而非长度。

**检索流程**

```mermaid
sequenceDiagram
    participant Q as 查询
    participant E as 嵌入模型
    participant V as 向量数据库
    participant R as 结果
    
    Q->>E: 查询文本
    E->>E: 生成查询向量
    E->>V: 向量搜索
    V->>V: 相似度计算
    V->>R: 返回 Top-K 结果
```

### 嵌入质量优化

**查询增强**

增强查询以提高检索效果：
- 查询扩展：添加同义词或相关术语
- 查询改写：使用 LLM 改写为更好的搜索形式
- 假设文档：生成假设的理想答案，用于检索

**文档增强**

优化文档嵌入：
- 添加标题前缀：将标题拼接到内容前
- 摘要增强：为每个块生成摘要，用摘要嵌入
- 多向量表示：同一内容生成多个嵌入

### 嵌入的局限与对策

**语义鸿沟**

嵌入基于字面语义，可能忽略领域特定含义。

对策：使用领域微调的嵌入模型，或结合关键词搜索。

**跨语言差异**

不同语言的嵌入质量可能不一致。

对策：选择多语言优化的模型，或翻译后检索。

**长尾查询**

罕见表达可能嵌入效果差。

对策：查询扩展，或结合多种检索方式。

### 嵌入模型更新

嵌入模型更新时需要注意：
- 重新生成全部文档嵌入
- 保持查询与文档使用相同模型
- 考虑过渡期的兼容性
