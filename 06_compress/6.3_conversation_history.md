## 6.3 对话历史管理

### 6.3.1 对话历史的挑战

多轮对话场景中，对话历史会持续增长，带来以下挑战：

- **上下文膨胀**：历史越长，占用上下文越多
- **信息稀释**：早期内容的相关性往往下降
- **成本累积**：每轮对话都包含完整历史，成本快速增加
- **性能下降**：过长上下文可能影响模型效果

### 6.3.2 对话历史管理策略

```mermaid
graph TB
    subgraph "历史管理策略"
        A["滑动窗口"]
        B["选择性保留"]
        C["对话压缩"]
        D["分层管理"]
    end
```

#### 滑动窗口

只保留最近 N 轮对话：

```
保留最近 5 轮：
[轮次 N-4] [轮次 N-3] [轮次 N-2] [轮次 N-1] [轮次 N]
```

**优点**：简单直接，实现容易
**缺点**：可能丢失重要的早期信息

**参数调优**：
- 窗口大小取决于任务特性
- 简单问答：2-5 轮
- 复杂任务：5-10 轮

#### 选择性保留

根据重要性选择保留哪些历史：

**重要性判断依据**：
- 包含任务关键信息
- 用户明确要求记住的内容
- 定义了重要约束或偏好
- 最近的交互

**实现方式**：
- 规则标记：基于关键词或模式
- 模型判断：让 LLM 评估重要性

#### 对话压缩

将冗长的对话历史压缩为摘要：

**即时压缩**

每轮对话后立即压缩：
```
[用户问]: 详细问题内容...
[助手答]: 详细回答内容...
→ 压缩为：用户询问了X，助手回答了Y的关键点
```

**批量压缩**

达到阈值后批量压缩较早的历史：
```
[早期10轮对话] → [压缩摘要]
[最近5轮对话] → [保持原文]
```

**递进压缩**

按时间距离采用不同压缩级别：
- 最近（1-3轮）：完整保留
- 近期（4-10轮）：轻度压缩
- 早期（10轮以上）：重度压缩

#### 分层管理

将对话信息分到不同层次存储：

| 层次 | 内容 | 存储位置 |
|------|------|----------|
| 工作层 | 当前对话上下文 | 上下文窗口 |
| 摘要层 | 对话历史摘要 | 上下文窗口 |
| 事实层 | 提取的关键事实 | 外部记忆 |
| 完整层 | 完整对话历史 | 持久存储 |

### 6.3.3 对话压缩的实现

#### 压缩提示词示例

```
请将以下对话历史压缩为简洁的摘要，保留：
1. 用户的主要需求和约束
2. 重要的决策和结论
3. 需要记住的上下文信息

原始对话：
[对话内容]

请生成不超过 200 字的摘要：
```

#### 信息提取式压缩

将对话转换为结构化信息：

```
从对话中提取：
- 用户目标：...
- 已确定的偏好：...
- 待解决的问题：...
- 当前状态：...
```

### 6.3.4 上下文拼接策略

整合不同来源的历史信息：

```
[系统提示词]
[用户画像/偏好]（从长期记忆）
[会话摘要]（早期历史的压缩）
[最近对话]（保留原文）
[当前问题]
```

### 6.3.5 最佳实践

1. **结合多种策略**：滑动窗口 + 压缩 + 重要信息提取

2. **保留关键锚点**：用户明确表达的约束始终保留

3. **自然过渡**：压缩后的内容应该与原文风格一致

4. **可恢复性**：保留完整历史供需要时回溯

5. **监控效果**：观察压缩是否影响对话质量
