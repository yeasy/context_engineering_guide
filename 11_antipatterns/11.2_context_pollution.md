## 11.2 上下文污染与隔离失效

### 11.2.1 现象描述

“把所有能找到的相关信息都塞给模型，让它自己从中挑选有用的。”这是最懒惰也最危险的策略。

### 11.2.2 反模式示例

> **错误做法（All-in Context）**：
> “这是关于该产品的所有文档（共 10 万字）：[...]”
> “User: 怎么重置密码？”

### 11.2.3 后果
*   **Lost in the Middle**：关键信息被淹没在海量噪音中，模型找不到答案。
*   **指令注入风险**：如果文档中包含恶意的 prompt（如来自网上的爬取数据），模型可能会被劫持。
*   **注意力分散**：模型可能会因为文档中的某句无关话语产生幻觉。

### 11.2.4 修正方案
*   **相关性过滤**：只检索最相关的 Top-K 片段，而不是整个文档。
*   **结构化隔离**：明确区分 `<context>` 和 `<instruction>`，告诉模型哪些是参考资料，哪些是指令。
