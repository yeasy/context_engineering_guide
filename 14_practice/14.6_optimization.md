## 14.6 持续迭代与改进

上线不是终点，而是数据闭环的起点。

### 14.6.1 评估体系

如何知道系统的回答好不好？不能只靠人的感觉。我们使用 **RAGAS** 框架进行自动化量化评估。
主要指标包括：
*   **Faithfulness (忠实度)**：回答是否忠实于检索到的上下文？（防幻觉）
*   **Answer Relevance (回答相关性)**：回答是否解决了用户的问题？
*   **Context Precision (上下文准确率)**：检索到的内容是否真的相关？

### 14.6.2 反馈闭环

在界面上设计点赞/点踩（👍/👎）按钮。
*   收集用户的负反馈（Bad Case）。
*   人工分析原因：是检索没找对？还是 LLM 理解错了？还是原始文档本身就有误？
*   将修正后的优质问答对加入 **微调数据集**，定期对 Embedding 模型或 LLM 进行微调 (Fine-tuning)，让模型越来越懂业务。

### 14.6.3 全链路监控

接入可观测性工具（如 LangSmith、LangFuse 等），记录每一次调用的完整 Trace（以工具版本与隐私合规要求为准）。
监控指标：
*   Token 消耗与成本
*   P99 延迟
*   Rerank 后的平均相关性得分

通过持续的数据观测和迭代，我们的知识库系统才能真正成为企业的“最强大脑”。
