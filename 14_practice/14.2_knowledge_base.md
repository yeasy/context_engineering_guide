# 14.2 知识库构建与向量化

高质量的数据是 RAG 系统效果的基石。本节我们将处理"垃圾进，垃圾出"（Garbage In, Garbage Out）的问题。

## 1. 数据清洗与预处理

### 1.1 格式统一
不同来源的文档需要转换为统一的中间格式（各类 Parser）。
*   **PDF**：使用 `PyMuPDF` 或 `Marker` 提取文本和表格。注意去除页眉页脚的干扰信息。
*   **Markdown**：保留标题层级结构（Header Metadata），这对于后续检索至关重要。
*   **Word/Excel**：使用 `python-docx` / `pandas` 提取内容。

### 1.2 清洗策略
*   去除乱码和不可见字符。
*   合并断行的段落（PDF常见问题）。
*   去除无意义的短文本（如"版权所有"）。

## 2. 文档分块 (Chunking)

我们在第 5 章讨论过分块策略，这里我们采用 **"语义分块" + "滑动窗口"** 的组合策略。

```python
# 伪代码示例：基于 Token 的滑动窗口分块
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,      # 块大小
    chunk_overlap=64,    # 重叠部分，保证上下文连续性
    separators=["\n\n", "\n", "。", "！", "？"] # 优先按段落和句子切分
)
```

**实战技巧**：
*   **父子索引 (Parent-Child Indexing)**：切分成小块（Child）用于向量检索，但检索到后返回其所属的大块（Parent）或全文给 LLM。这能兼顾检索的精准度和上下文的完整性。

## 3. 向量化 (Embedding)

### 3.1 模型选择
推荐使用 [MTEB](https://huggingface.co/spaces/mteb/leaderboard) 榜单上的前沿模型。
*   **开源推荐**：`BAAI/bge-m3`（支持稀疏检索）、`intfloat/multilingual-e5-large`。
*   **闭源推荐**：`text-embedding-3-large` (OpenAI)。

### 3.2 向量库写入
使用 Milvus 或 Chroma 存储向量。务必为每个 Chunk 附带元数据（Metadata）：
*   `source`: 来源文件名
*   `page`: 页码
*   `created_at`: 创建时间
*   `category`: 文档分类（用于后续过滤）

```json
{
  "content": "公司差旅报销标准...",
  "vector": [0.12, -0.05, ...],
  "metadata": {
    "source": "员工手册2026版.pdf",
    "page": 12,
    "category": "HR"
  }
}
```
