## 14.4 对话历史管理

在多轮对话中，单纯拼接所有历史记录会迅速耗尽 Token 窗口，并引入噪声。

### 14.4.1 上下文选择策略

我们在[第 6 章](../6_compress/6.3_conversation_history.md)介绍了多种压缩策略，在实战中我们采用 **滑动窗口** + **摘要** 策略。

#### 滑动窗口
保留最近的 K 轮对话（如最近 5 轮）。这能保证对当前话题的即时响应能力。

#### 摘要
对于超出窗口的早期对话，定期调用 LLM 生成摘要。
*   **触发时机**：每当积累 5 轮对话，或 Token 数超过阈值时。
*   **存储方式**：将摘要文本作为 System Prompt 的一部分植入。

### 14.4.2 上下文组装

最终发送给 LLM 的 Prompt 结构如下：

```markdown
<system_prompt>
你是一个智能企业助手。
以下是之前的对话摘要：{summary}
</system_prompt>

<context>
相关文档片段：
1. {chunk_1} (来源: doc_a.pdf)
2. {chunk_2} (来源: doc_b.md)
...
</context>

<chat_history>
User: 上次说到的报销额度是多少？
Assistant: 根据规定，单笔限额为 5000 元。
</chat_history>

<user_query>
User: {current_query}
</user_query>
```

这种结构化设计（Isolation 策略）能有效防止指令注入，并帮助 LLM 区分哪些是参考资料，哪些是对话内容。
